<p align="center">
  <img src="https://github.com/user-attachments/assets/973a48c3-829c-4b4c-9479-48341ba518a4" alt="RemoteRL Banner" style="max-width:100%; height:auto;"/>
</p>

# RemoteRL â€“ Remote Reinforcement Learning for Everyone, Everywhere ğŸš€
> **Cloud-native RL in a single line of code**

[![PyPI](https://img.shields.io/pypi/v/remoterl)](https://pypi.org/project/remoterl/)
[![Python 3.10â€“3.12](https://img.shields.io/static/v1?label=python&message=3.10â€“3.12&logo=python&color=blue)](#)
[![Platforms](https://img.shields.io/badge/platforms-Linux%20%7C%20Windows%20%7C%20MacOS-blue)](#)
[![Gymnasium](https://img.shields.io/static/v1?label=gymnasium&message=%20&color=blue&logo=pypi)](https://pypi.org/project/gymnasium/)
[![Websockets](https://img.shields.io/static/v1?label=websockets&message=%20&color=blue&logo=pypi)](https://pypi.org/project/websockets/)
[![Extras](https://img.shields.io/static/v1?label=extras&message=ray[rllib])](#)
[![Extras](https://img.shields.io/static/v1?label=extras&message=stable-baselines3)](#)
[![Dependencies](https://img.shields.io/librariesio/release/pypi/remoterl)](https://pypi.org/project/remoterl/)

* **[Installation](#-installation)** Â· **[Configure Key](#-configure-your-api-key)** Â· **[Helloâ€‘World Example](#-hello-world-example)** Â· **[Next Steps](#-next-steps)**

---

## ğŸ§© How It Works â€” Three Pieces Mental Model


<div align="center">

Simulator(s)/Robot(s)&emsp;â‡„&emsp;ğŸŒ RemoteRL Relay&emsp;â‡„&emsp;Trainer (GPU/Laptop)

</div>


<p align="center">
  <img width="723" alt="RemoteRL Service Flow" src="https://github.com/user-attachments/assets/c792c0f1-4461-4b13-ade4-0b344eb9ff69" />
</p>

> The **trainer** sends actions, the **simulator** steps the environment, and the relay moves encrypted messages between them. Nothing else to install, no ports to open.
>
> * **Isolated runtimes** â€“ trainer and simulator can run different Python or OS stacks.
> * **Elastic scale** â€“ fan in 1â€¦N simulators, or fan out distributed learner workers.
> * **Always encrypted, never stored** â€“ payloads travel via TLS and are dropped after delivery.
> * **Free tier:** every account includes **1 GB of data credit(per month)** (â‰ˆ 1 M CartPole steps).


---


## ğŸ“¦ Installation

```bash
# Gymnasium only (lightweight)
pip install remoterl

# + Stableâ€‘Baselines3
pip install remoterl stable-baselines3

# + Ray RLlib
pip install remoterl "ray[rllib]" torch pillow
```

---

## ğŸ” Configure Your API Key

To use RemoteRL, you need an API key.
You can get it either via CLI or from the website:

### Option 1 â€” CLI (Recommended)

```bash
remoterl register  # Opens browser and fetches your API key automatically
```
The key will be saved to your local config automatically.

### Option 2 â€” Manual (for server, CI, or scripts)
1. Visit [remoterl.com/signup](https://remoterl.com/signup) and **sign up for an account**
2. Go to your Dashboard
3. Copy your API key

Set it as an environment variable:
```bash
export REMOTERL_API_KEY=api_xxxxx...
```


## ğŸ’» Hello World Example

### Run **two terminals**:

```bash
# Terminal A â€“ simulator
$ remoterl simulate

# Terminal B â€“ trainer
$ remoterl train 
```
  
<details>

<summary><code>remoterl simulate</code> â€” Python example</summary>

```python
import remoterl

# 1. Decide at runtime whether this process is the trainer or the simulator
remoterl.init(role="simulator")  # blocks
remoterl.shutdown()  # optional
```
</details>

<details>
<summary><code>remoterl train</code> â€” Python example</summary>

```python
import gymnasium as gym
import remoterl

remoterl.init(role="trainer")        # one call switches to remote mode

env = gym.make("CartPole-v1")        # actually runs on the simulator
obs, _ = env.reset()
for _ in range(1_000):
    action = env.action_space.sample()
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated or truncated:
        obs, _ = env.reset()
```
</details>

Thatâ€™s it â€“ youâ€™ve split CartPole across the network.


## âš¡ Latency & Isolation

| Path                            | Typical RTT | Notes                               |
| ------------------------------- | ----------- | ----------------------------------- |
| TrainerÂ â†” sameâ€‘region simulator | 10â€‘50â€¯ms    | Feels like local play.              |
| TrainerÂ â†” crossâ€‘continent       | 50â€‘150â€¯ms   | Use frameâ€‘skip for twitchy control. |

---

## ğŸ“š Next Steps


* **[`Cloud Service Overview`](<./docs/Overview/overview-cloud-service.md>)** â€“ details on what it is and how it works.  
* **[`Console-Output Guide`](<./docs/SDKÂ (Python)/sdk-console-output-guide.md>)** â€“  step-by-step screenshots from a *live* trainer â†” simulator session, with every line highlighted and explained.  
* **[`Quick-Start (Init & Shutdown)`](<./docs/SDKÂ (Python)/sdk-quick-start-init-shutdown.md>)** â€“ step-by-step examples of `remoterl.init()` and `remoterl.shutdown()` for trainers and simulators.  
* **[`Trainer Cheat-sheet`](<./docs/SDKÂ (Python)/sdk-trainer-remote-call-cheat-sheet.md>)** â€“ Gymnasium, Stable-Baselines3, and RLlib one-liners for remote execution.  

## ğŸ“ Quick Links

- ğŸ”‘ [Get your API Key](https://remoterl.com) â€“ Create an account on the official site to get your key.
- ğŸ“Š [RemoteRL Dashboard](https://remoterl.com/user/dashboard) â€“ Manage your usage, keys, and settings.
- ğŸ“˜ [Documentation Index](./docs/Overview/overview-cloud-service.md) â€“ Start from the top-level service overview.

---
 
## ğŸ“„ License 

RemoteRL is distributed under a commercial license.
We offer a free tier, while premium plans help offset our worldwide cloud-server costs. See [`LICENSE`](./LICENSE.txt) for details.

---


**Happy remote training!** ğŸ¯
